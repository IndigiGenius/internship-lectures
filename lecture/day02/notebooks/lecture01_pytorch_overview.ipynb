{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "975161c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e1ab88",
   "metadata": {},
   "source": [
    "# Introduction to PyTorch\n",
    "\n",
    "## Schedule\n",
    "\n",
    "### PyTorch Overview\n",
    "\n",
    "- What is PyTorch?\n",
    "- Applications\n",
    "- History\n",
    "- Overview of PyTorch Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35071a7",
   "metadata": {},
   "source": [
    "### What is PyTorch?\n",
    "\n",
    "> Pytorch is an optimized tensor library for deep learning using GPUs and CPUs.\n",
    "\n",
    "But what does that really mean?\n",
    "\n",
    "#### What is a tensor\n",
    "For the purposes of machine learning, a tensor is a multi-dimensional array.\n",
    "You are familiar with one-dimensional arrays, it is just a row vector:\n",
    "$$\n",
    "\\left(\n",
    "  \\begin{array}{cccc}\n",
    "    1 & 2 & 3 & 4\n",
    "  \\end{array}\n",
    "\\right)\n",
    "$$\n",
    "and you are familiar with two-dimensional arrays, which is just a matrix:\n",
    "$$\n",
    "\\left(\n",
    "  \\begin{array}{cc}\n",
    "    1 & 0 \\\\\n",
    "    0 & 1\n",
    "  \\end{array}\n",
    "\\right)\n",
    "$$\n",
    "A tensor extends this analogy to multiple dimensions.\n",
    "\n",
    "The main reason we need to extend this analogy is that the data we will work with is more naturally stored in tensors.\n",
    "For example, images are typically stored in rgb (red, green, blue) format.\n",
    "So, each image consists of a red part, a green part, and a blue part.\n",
    "Each of these parts consists of a matrix that encodes the intensity of a pixel of that part.\n",
    "An image is stored as 3 $2 \\times 2$ matrices, or in other words, which we will make more precise, it is a tensor with dimensions or shape $(3, H, W)$ or $(H, W, 3)$, depending on the format you are storing it in, here $H$ denotes height, and $W$ denotes width.\n",
    "When we want to train a machine learning model, we typically \"batch\" multiple samples together and so a batch of images would be a tensor with dimensions or shape $(B, 3, H, W)$ or $(B, H, W, 3)$, where $B$ is the number of samples in the batch.\n",
    "\n",
    "Similary, if we have text, it will be tokenized, we'll talk more about that later, it will be in a multi-dimensional tensor.\n",
    "Typically, it is of the form $(B, L)$ or $(B, 1, L)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaf2fc6",
   "metadata": {},
   "source": [
    "#### What is deep learning?\n",
    "\n",
    "Deep learning is a term that is beginning to fall out of fashion, replaced by older, yet newer words such as Artificial Intelligence.\n",
    "Deep learning is the field of neural networks with many layers.\n",
    "Mathematically, if $f_{k}$ for $k = 1, 2, \\dots, d$ are functions of the form\n",
    "$$\n",
    "f_{k}(\\mathbf{x}) = g_{k}(\\mathbf{A}_{k}\\mathbf{x} + \\mathbf{b}_{k}, \\mathbf{x})\n",
    "$$\n",
    "where $\\mathbf{x} \\in \\mathbb{R}^{n_{k - 1} \\times 1}$, $\\mathbf{A}_{k}$ is an $n_{k} \\times m$ matrix and $\\mathbf{b}_{k} \\in \\mathbb{R}^{n_{k} \\times 1}$ and $n_{0} = m$ and $g_{k}: \\mathbb{R}^{n_{k} \\times 1} \\times \\mathbb{R}^{n_{k - 1} \\times 1} \\to \\mathbb{R}^{n_{k} \\times 1}$.\n",
    "Or in other words, a layer is an affine function composed with a non-linear function.\n",
    "It should be noted that, $g_{k}$'s range is for mathematical convenience.\n",
    "It should also be noted that often the $g_{k}$ functions operate component-wise.\n",
    "That is, if we have a vector\n",
    "$$\n",
    "\\textbf{x} =\n",
    "\\left(\n",
    "\\begin{array}{c}\n",
    "1 \\\\\n",
    "2 \\\\\n",
    "3 \\\\\n",
    "4\n",
    "\\end{array}\n",
    "\\right)\n",
    "$$\n",
    "then\n",
    "$$\n",
    "g(\\textbf{x}) =\n",
    "\\left(\n",
    "\\begin{array}{c}\n",
    "g(1) \\\\\n",
    "g(2) \\\\\n",
    "g(3) \\\\\n",
    "g(4)\n",
    "\\end{array}\n",
    "\\right)\n",
    "$$ \n",
    "\n",
    "There isn't a really set number for how deep a neural network has to be before it's considered a deep neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee439b13",
   "metadata": {},
   "source": [
    "### Why GPUs?\n",
    "\n",
    "PyTorch is optimized for both GPUs and CPUs, but the primary use case is GPUs.\n",
    "So, why GPUs?\n",
    "As noted before, there are a few neural network components that comprise the majority of FLOPs (FLoating point OPerations):\n",
    "- matrix matrix multiplication\n",
    "- matrix vector multiplication\n",
    "- matrix and vector addition\n",
    "- component-wise functions.\n",
    "All of these components are operations that are highly parallelizable.\n",
    "\n",
    "CPUs are typically composed of a large amount of cache and a large control unit with a few arithmetic logic units (ALU).\n",
    "GPUs, on the other hand, have a lot of small pieces of cache with a lot of small control units with a large amount of ALUs.\n",
    "Further, the chip is divided up in such a way that each individual cache and each invidual control unit controls multiple ALUs.\n",
    "This is possible, because it is expected that multiple ALUs will be performing the same type of operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9828a142",
   "metadata": {},
   "source": [
    "### Applications\n",
    "\n",
    "Deep learning has found a large range of applications:\n",
    "- image recognition\n",
    "- objection detection\n",
    "- image segmentation\n",
    "- automatic speech transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87909a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
